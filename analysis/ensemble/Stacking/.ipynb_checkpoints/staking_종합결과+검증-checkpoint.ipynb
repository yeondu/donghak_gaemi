{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85a4a63",
   "metadata": {},
   "source": [
    "# 기본 패키지 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679b7d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:49.986558Z",
     "start_time": "2021-09-02T17:42:37.101238Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier # 앙상블 \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report # 정오분류표\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,classification_report,confusion_matrix  # ROC곡선 그리기\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import learning_curve, validation_curve # 학습곡선, 검증곡선\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score  # 하이퍼파라미터 튜닝, 교차타당도\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6e107",
   "metadata": {},
   "source": [
    "# 데이터 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba254d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:50.353556Z",
     "start_time": "2021-09-02T17:42:49.993557Z"
    }
   },
   "outputs": [],
   "source": [
    "naver_df = pd.read_csv(\"../../data/baseline_data.csv\", \n",
    "                       index_col=['Date'], parse_dates=True)\n",
    "hyundai_df = pd.read_csv(\"../../data/HyundaiMtr.csv\", \n",
    "                       index_col=['Date'], parse_dates=True)\n",
    "LG_df = pd.read_csv(\"../../data/LGCHEM.csv\", \n",
    "                       index_col=['Date'], parse_dates=True)\n",
    "Samsung_df = pd.read_csv(\"../../data/samsungElec.csv\", \n",
    "                       index_col=['Date'], parse_dates=True)\n",
    "amore_df = pd.read_csv(\"../../data/AmorePacific.csv\", \n",
    "                       index_col=['Date'], parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3369d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:50.369558Z",
     "start_time": "2021-09-02T17:42:50.358556Z"
    }
   },
   "outputs": [],
   "source": [
    "def labeling(origin_df):\n",
    "    n_list = [1,3,5,7,10,20,30,60,90]\n",
    "    for n in n_list:\n",
    "        col_name = 'next_price'+str(n)\n",
    "        origin_df[col_name] = origin_df['Close'].shift(-n)\n",
    "        diffs = origin_df[col_name]-origin_df['Close']\n",
    "        label_name = 'label'+str(n)\n",
    "        origin_df[label_name] = np.where(diffs>0,1,0)\n",
    "        \n",
    "        df = origin_df['2011-01-01':'2020-12-31']\n",
    "        df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf161a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:51.104558Z",
     "start_time": "2021-09-02T17:42:50.375555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "naver_df = labeling(naver_df)\n",
    "hyundai_df = labeling(hyundai_df)\n",
    "LG_df = labeling(LG_df)\n",
    "Samsung_df = labeling(Samsung_df)\n",
    "amore_df = labeling(amore_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b636a93",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0398840",
   "metadata": {},
   "source": [
    "## Column List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8481fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:51.118555Z",
     "start_time": "2021-09-02T17:42:51.109556Z"
    }
   },
   "outputs": [],
   "source": [
    "feature1_list = ['Open','High','Low','Adj Close','Volume','log_return','Close','next_rtn']\n",
    "feature2_list = ['RASD5','RASD10','ub','lb','CCI','ATR','MACD','MA5','MA10','MTM1','MTM3','ROC','WPR','middle']\n",
    "feature3_list = ['S&P500', 'SOX', 'VIX','KOSPI']\n",
    "feature4_list = ['next_price']\n",
    "all_x_feature = feature1_list+feature2_list+feature3_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4a98a",
   "metadata": {},
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73e033d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:51.140559Z",
     "start_time": "2021-09-02T17:42:51.123560Z"
    }
   },
   "outputs": [],
   "source": [
    "# 스태킹 함수\n",
    "def get_stacking_datasets(model, Xtrain, ytrain, Xtest, n_folds=5):\n",
    "  # cv하기 위해 K-fold 설정\n",
    "  kfold = KFold(n_splits=n_folds, shuffle=True, random_state=1234)\n",
    "\n",
    "  # 최종 메타 모델이 사용할 학습 데이터 반환을 위해서 넘파이 배열을 0으로 만들어서 초기화\n",
    "  train_fold_pred = np.zeros((Xtrain.shape[0], 1)) # 2차원\n",
    "  test_pred = np.zeros((Xtest.shape[0], n_folds))\n",
    "  #print('model: ', model.__class__.__name__)\n",
    "\n",
    "  for cnt, (train_index, valid_index) in enumerate(kfold.split(Xtrain)):\n",
    "    # 개별 모델 내부에서 학습하고 1개의 fold로 예측할 데이터셋 추출\n",
    "    #print(f\" Fold 횟수 : {cnt+1}\")\n",
    "    X_tr = Xtrain[train_index]\n",
    "    y_tr = ytrain[train_index]\n",
    "    X_validation = Xtrain[valid_index]\n",
    "\n",
    "    # 학습\n",
    "    model.fit(X_tr, y_tr)\n",
    "    # 1개의 fold데이터셋으로 예측값 반환 후 최종 메타모델이 학습할 데이터셋에 첨가\n",
    "    train_fold_pred[valid_index, :] = model.predict(X_validation).reshape(-1, 1)\n",
    "    # 해당 폴드에서 생성된 모델에게 원본 테스트 데이터(Xtest)를 이용해서 예측을 수행하고 저장\n",
    "    test_pred[:, cnt] = model.predict(Xtest)\n",
    "\n",
    "  # 개별 모델 안에서 테스트 데이터셋을 기반으로 예측한 결과값들 mean 취해주고 2차원으로 바꾸기\n",
    "  test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "\n",
    "  return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2312f2",
   "metadata": {},
   "source": [
    "## Stratified Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b479fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:51.161558Z",
     "start_time": "2021-09-02T17:42:51.148555Z"
    }
   },
   "outputs": [],
   "source": [
    "#스태킹 함수\n",
    "def get_stacking_datasets2(model, X_train, y_train, X_test, n_folds=5):\n",
    "  skf = StratifiedKFold(n_splits=n_folds)\n",
    "\n",
    "  # 최종 메타 모델이 사용할 학습 데이터 반환을 위해서 넘파이 배열을 0으로 만들어서 초기화\n",
    "  train_fold_pred2 = np.zeros((X_train.shape[0], 1))\n",
    "\n",
    "  test_pred2 = np.zeros((X_test.shape[0], n_folds))\n",
    "  #print('model: ', model.__class__.__name__)\n",
    "\n",
    "  for cnt, (train_index, valid_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    # 개별 모델 내부에서 학습하고 1개의 fold로 예측할 데이터셋 추출\n",
    "    #print(f\" Fold 횟수 : {cnt+1}\")\n",
    "    X_tr2 = X_train[train_index]\n",
    "    y_tr2 = y_train[train_index] \n",
    "    X_validation = X_train[valid_index]\n",
    "\n",
    "    # 학습\n",
    "    model.fit(X_tr2, y_tr2)\n",
    "    # 1개의 fold데이터셋으로 예측값 반환 후 최종 메타모델이 학습할 데이터셋에 첨가\n",
    "    train_fold_pred2[valid_index,:] = model.predict(X_validation).reshape(-1, 1)\n",
    "     # 해당 폴드에서 생성된 모델에게 원본 테스트 데이터(X_test)를 이용해서 예측을 수행하고 저장\n",
    "    test_pred2[:, cnt] = model.predict(X_test)\n",
    "\n",
    "  test_pred_mean2 = np.mean(test_pred2, axis=1).reshape(-1, 1)\n",
    "  return train_fold_pred2, test_pred_mean2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d361456",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08dbd18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:51.214095Z",
     "start_time": "2021-09-02T17:42:51.167558Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_trend(label_list,df_list,stock_list):\n",
    "    result = pd.DataFrame(\n",
    "                      index=['ADA', 'LGBM','XGB','RF',\n",
    "                               'Staking','KFold-Staking','StratifiedKFold'])\n",
    "\n",
    "    for df,stock_name in zip(df_list,stock_list):\n",
    "        print('-----',stock_name,'시작합니다.-----')\n",
    "        for n in label_list:\n",
    "\n",
    "            if set(df.columns[:27]) == set(all_x_feature + feature4_list):\n",
    "                X = df[all_x_feature]\n",
    "\n",
    "                # Min Max Scaler를 사용해 스케일링\n",
    "                scaler = MinMaxScaler()\n",
    "                scaler.fit(X)\n",
    "                X_scaled = scaler.transform(X)\n",
    "\n",
    "                label_name = 'label'+str(n)\n",
    "                y = df[label_name]\n",
    "\n",
    "                # train test split\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=1234, \n",
    "                                                                    stratify=y)\n",
    "\n",
    "                print('Lable'+str(n)+' 양성비율','train : %.3f' %(sum(y_train)/len(y_train)),end=' ')\n",
    "                print('test : %.3f' %(sum(y_test)/len(y_test)))\n",
    "\n",
    "                #tree\n",
    "                tree = DecisionTreeClassifier(max_depth=4,\n",
    "                                              criterion='entropy',\n",
    "                                              random_state=1234)\n",
    "                # Ada\n",
    "                adaboost = AdaBoostClassifier(base_estimator=tree, \n",
    "                                        n_estimators=100,\n",
    "                                        learning_rate = 0.01, \n",
    "                                        random_state=1234)\n",
    "                # lgb\n",
    "                lgb = LGBMClassifier(random_state=1234)\n",
    "\n",
    "                # xgb\n",
    "                xgb = XGBClassifier(tree_method='hist',random_state=41)\n",
    "\n",
    "                # rf\n",
    "                forest = RandomForestClassifier(criterion='entropy',\n",
    "                                                n_estimators=700,\n",
    "                                                random_state=1234)\n",
    "                # stacking\n",
    "\n",
    "\n",
    "                all_clf = [adaboost,lgb,xgb,forest]\n",
    "                clf_label = ['ADA', 'LGBM','XGB','RF']\n",
    "\n",
    "                pred = []\n",
    "                stack_final_x_train = []\n",
    "                stack_final_x_train2 = []\n",
    "                stack_final_x_test = []\n",
    "                stack_final_x_test2 = []\n",
    "                acc = []\n",
    "\n",
    "                for clf,label in zip(all_clf,clf_label):\n",
    "                    clf.fit(X_train,y_train)\n",
    "                    y_pred = clf.predict(X_test)\n",
    "\n",
    "                    pred.append(y_pred)\n",
    "                    acc.append(round(accuracy_score(y_test, y_pred),2))\n",
    "                    clf_train, clf_test = get_stacking_datasets(clf,X_train,y_train, X_test)\n",
    "                    stack_final_x_train.append(clf_train)\n",
    "                    stack_final_x_test.append(clf_test)\n",
    "\n",
    "                    clf_train2, clf_test2 = get_stacking_datasets2(clf,X_train,y_train, X_test)\n",
    "                    stack_final_x_train2.append(clf_train2)\n",
    "                    stack_final_x_test2.append(clf_test2)\n",
    "\n",
    "\n",
    "                # Staking\n",
    "                pred = np.transpose(pred)\n",
    "                lr_final = LogisticRegression(C=10)\n",
    "                lr_final.fit(pred, y_test)\n",
    "                final = lr_final.predict(pred)\n",
    "\n",
    "                acc.append(round(accuracy_score(final, y_test),2))\n",
    "\n",
    "\n",
    "                # KFold\n",
    "                stack_final_x_train = np.concatenate(tuple(stack_final_x_train), axis=1)\n",
    "                stack_final_x_test = np.concatenate(tuple(stack_final_x_test), axis=1)\n",
    "                lr_final = LogisticRegression(C=10)\n",
    "                lr_final.fit(stack_final_x_train, y_train)\n",
    "                stack_final_pred = lr_final.predict(stack_final_x_test)\n",
    "                acc.append(round(accuracy_score(stack_final_pred, y_test),2))\n",
    "\n",
    "                # Stratified KFold\n",
    "                stack_final_x_train2 = np.concatenate(tuple(stack_final_x_train2), axis=1)\n",
    "                stack_final_x_test2 = np.concatenate(tuple(stack_final_x_test2), axis=1)\n",
    "                lr_final = LogisticRegression(C=10)\n",
    "                lr_final.fit(stack_final_x_train2, y_train)\n",
    "                stack_final_pred2 = lr_final.predict(stack_final_x_test2)\n",
    "                acc.append(round(accuracy_score(stack_final_pred2, y_test),2))\n",
    "\n",
    "                col_name = stock_name + str(n)\n",
    "                result[col_name] = acc\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cddda33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:42:51.237098Z",
     "start_time": "2021-09-02T17:42:51.219101Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list= [1,7,30,90]\n",
    "df_list = [naver_df,hyundai_df,LG_df,Samsung_df,amore_df]\n",
    "stock_list = ['naver','hyundai','LG','Samsung','amore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a483340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:44:44.449166Z",
     "start_time": "2021-09-02T17:42:51.245097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- naver 시작합니다.-----\n",
      "Lable1 양성비율 train : 0.480 test : 0.480\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b2c7c5091545>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_trend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstock_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-701536864735>\u001b[0m in \u001b[0;36mpredict_trend\u001b[1;34m(label_list, df_list, stock_list)\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                     \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                     \u001b[0mclf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stacking_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                     \u001b[0mstack_final_x_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[0mstack_final_x_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c3fb59695b1f>\u001b[0m in \u001b[0;36mget_stacking_datasets\u001b[1;34m(model, Xtrain, ytrain, Xtest, n_folds)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 1개의 fold데이터셋으로 예측값 반환 후 최종 메타모델이 학습할 데이터셋에 첨가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtrain_fold_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 393\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    908\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "acc_df = predict_trend(label_list,df_list,stock_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4bf57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:44:44.459169Z",
     "start_time": "2021-09-02T17:42:37.094Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0fa58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:44:44.460196Z",
     "start_time": "2021-09-02T17:42:37.098Z"
    }
   },
   "outputs": [],
   "source": [
    "col_list = [stock + str(label) for label in label_list for stock in stock_list]\n",
    "acc_df = acc_df[col_list].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bbf6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:44:44.462166Z",
     "start_time": "2021-09-02T17:42:37.105Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe092a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T17:44:44.464159Z",
     "start_time": "2021-09-02T17:42:37.108Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "day = datetime.today().day\n",
    "Path = \"../../data/stacking_result\"+str(day)+\".xlsx\" \n",
    "acc_df.to_excel(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d73ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
